{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from group_lasso import GroupLasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_dataset.csv')\n",
    "train_top = pd.read_csv('train_dataset_top.csv')\n",
    "train_bottom = pd.read_csv('train_dataset_bot.csv')\n",
    "\n",
    "test = pd.read_csv('test_dataset.csv')\n",
    "test_top = pd.read_csv('test_dataset_top.csv')\n",
    "test_bottom = pd.read_csv('test_dataset_bot.csv')\n",
    "\n",
    "val= pd.read_csv('val_dataset.csv')\n",
    "val_top = pd.read_csv('val_dataset_top.csv')\n",
    "val_bottom = pd.read_csv('val_dataset_bot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(test.columns[0], axis=1, inplace=True)\n",
    "test.dropna(inplace=True)\n",
    "\n",
    "train.drop(train.columns[0], axis=1, inplace=True)\n",
    "train.dropna(inplace=True)\n",
    "\n",
    "val.drop(val.columns[0], axis=1, inplace=True)\n",
    "val.dropna(inplace=True)\n",
    "\n",
    "test_top.drop(test_top.columns[0], axis=1, inplace=True)\n",
    "test_top.dropna(inplace=True)\n",
    "\n",
    "train_top.drop(train_top.columns[0], axis=1, inplace=True)\n",
    "train_top.dropna(inplace=True)\n",
    "\n",
    "val_top.drop(val_top.columns[0], axis=1, inplace=True)\n",
    "val_top.dropna(inplace=True)\n",
    "\n",
    "test_bottom.drop(test_bottom.columns[0], axis=1, inplace=True)\n",
    "test_bottom.dropna(inplace=True)\n",
    "\n",
    "train_bottom.drop(train_bottom.columns[0], axis=1, inplace=True)\n",
    "train_bottom.dropna(inplace=True)\n",
    "\n",
    "val_bottom.drop(val_bottom.columns[0], axis=1, inplace=True)\n",
    "val_bottom.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of Sample R-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_oss(true,pred):\n",
    "    true = np.array(true)\n",
    "    pred = np.array(pred).flatten()\n",
    "    print(true)\n",
    "    print(pred)\n",
    "    numer = np.dot((true-pred),(true-pred))\n",
    "    denom = np.dot(true,true)\n",
    "    frac = numer/denom\n",
    "    return 1-frac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huber loss function calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HuberLoss(true,pred,epsilon):\n",
    "    true=true.reshape((true.shape[0],1))\n",
    "    residual = true-pred\n",
    "    huber_loss = np.where((np.abs(residual)<1),residual**2,2*epsilon*(np.abs(residual)-0.5*epsilon))\n",
    "    return np.mean(huber_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accelerated Proximal Gradient (APG) Algorithm (non-GLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S(x,mu):\n",
    "    x = np.where(np.abs(x)<=mu, 0, x)\n",
    "    x = np.where((np.abs(x)>mu) & (x>0), x-mu, x)\n",
    "    x = np.where((np.abs(x)>mu) & (x<0), x+mu, x)\n",
    "    return x\n",
    "\n",
    "def mse_grad(theta,X,y):\n",
    "    n = len(y)\n",
    "    error = X@theta-y\n",
    "    return (2/n)*X.T@error\n",
    "\n",
    "def huber_grad(theta,X,y,epsilon):\n",
    "    error = X @ theta - y\n",
    "    delta_abs = np.abs(error)\n",
    "\n",
    "    gradient = np.zeros_like(theta)\n",
    "\n",
    "    mask = delta_abs <= epsilon\n",
    "    indices = np.where(mask)[0]\n",
    "    if np.any(delta_abs[indices] == 0):\n",
    "        gradient += 0\n",
    "    else:\n",
    "        gradient += X[indices].T @ (error[indices] / delta_abs[indices])\n",
    "\n",
    "    mask = delta_abs > epsilon\n",
    "    indices = np.where(mask)[0]\n",
    "    modifier = epsilon * np.sign(error[indices]).T @ X[indices]\n",
    "    gradient = gradient+modifier.T\n",
    "    gradient /= len(y)\n",
    "\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def proximal_ridge_operator(theta,gamma,lamda):\n",
    "    return theta/(1+(lamda*gamma))\n",
    "\n",
    "def proximal_lasso_operator(theta,gamma,lamda):\n",
    "    return lamda*S(x=theta,mu=lamda*gamma)\n",
    "\n",
    "def proximal_elastic_operator(theta,gamma,lamda,rho):\n",
    "    return (1/(1+(lamda*gamma*rho)))*S(x=theta,mu=(1-rho)*lamda*gamma)\n",
    "\n",
    "def theta_bar(theta,gamma,grad_loss):\n",
    "    return theta-gamma*grad_loss\n",
    "\n",
    "def theta_tilde(theta_bar,gamma,lamda,model,rho=None):\n",
    "    if model == 'ridge':\n",
    "        return proximal_ridge_operator(theta_bar,gamma,lamda)\n",
    "    elif model == 'lasso':\n",
    "        return proximal_lasso_operator(theta_bar,gamma,lamda)\n",
    "    elif model == 'elastic':\n",
    "        return proximal_elastic_operator(theta_bar,gamma,lamda,rho)\n",
    "    \n",
    "def prox_grad(gamma,lamda,X,y,model,loss_type,max_iter=1000,tol=1e-5,rho=None,epsilon=1):\n",
    "    K = X.shape[1]\n",
    "    X = np.array(X)\n",
    "    N = len(y)\n",
    "    y = np.array(y).reshape((N,1))\n",
    "    theta = np.zeros((K,1))\n",
    "    m=0\n",
    "    if loss_type == 'huber':\n",
    "        for _ in np.arange(max_iter):\n",
    "            theta_m = theta\n",
    "            grad_loss = huber_grad(theta=theta_m,X=X,y=y,epsilon=epsilon)\n",
    "            theta_b = theta_bar(theta=theta_m,gamma=gamma,grad_loss=grad_loss)\n",
    "            theta_t = theta_tilde(theta_bar=theta_b,gamma=gamma,lamda=lamda,model=model,rho=rho)\n",
    "            theta = theta_t + ((m/(m+3))*(theta_t-theta_m))\n",
    "            m+=1\n",
    "            if np.sum(np.abs(theta-theta_m)) == 0 or np.sum((theta-theta_m)**2) < np.sum(theta_m**2*tol):\n",
    "                break\n",
    "    elif loss_type == 'mse':\n",
    "        for m in np.arange(max_iter):\n",
    "            theta_m = theta\n",
    "            grad_loss = mse_grad(theta=theta_m,X=X,y=y)\n",
    "            theta_b = theta_bar(theta=theta_m,gamma=gamma,grad_loss=grad_loss)\n",
    "            theta_t = theta_tilde(theta_bar=theta_b,gamma=gamma,lamda=lamda,model=model,rho=rho)\n",
    "            theta = theta_t + ((m/(m+3))*(theta_t-theta_m))\n",
    "            m+=1\n",
    "            if np.sum(np.abs(theta-theta_m)) == 0 or np.sum((theta-theta_m)**2) < np.sum(theta_m**2*tol):\n",
    "                break\n",
    "    return theta\n",
    "\n",
    "def fit_APG(Xtest,theta):\n",
    "    return Xtest@theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model using OLS and MSE as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.088191  0.079484 -0.015975 ...  0.071545 -0.065069 -0.076855]\n",
      "[0.19138025 0.01578328 0.20153042 ... 0.19497756 0.30559985 0.60147626]\n",
      "In sample R2 value for complete dataset is: -0.518376168525575\n",
      "\n",
      "Out of sample R2 value for complete dataset is: -0.5137208520749783\n",
      "\n",
      "[-0.185185 -0.0625   -0.21123  ...  0.157965 -0.171607  0.001463]\n",
      "[1.01884168 0.86161526 0.80864023 ... 1.0378286  1.05825458 1.01575586]\n",
      "In sample R2 value for bottom performers of dataset is: -5.907567952931123\n",
      "\n",
      "Out of sample R2 value for bottom performers of dataset is: -5.887329848358863\n",
      "\n",
      "[ 0.074229 -0.068037 -0.001236 ...  0.152268  0.10736   0.010708]\n",
      "[ 0.2180384   0.14648726  0.0863384  ... -0.21565593 -0.06696754\n",
      "  0.06547352]\n",
      "In sample R2 value for top performers of dataset is: -2.191340991685312\n",
      "\n",
      "Out of sample R2 value for top performers of dataset is: -2.1504202290179615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtrain = [train.drop(columns=['DATE','permno','RET']).values,train_bottom.drop(columns=['DATE','permno','RET']).values,train_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test.drop(columns=['DATE','permno','RET']).values,test_bottom.drop(columns=['DATE','permno','RET']).values,test_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "i = 0\n",
    "while i<3:\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    pred = model.predict(X=Xtest[i])\n",
    "    R2 = r2_score(y_true=Ytrue[i],y_pred=pred)\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=pred)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "        df = pd.DataFrame({'permno':test_top['permno'],'date':test_top['DATE'],'ret':test_top['RET'],'pred':pred})\n",
    "        df.to_csv('OLS_MSE.csv')\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model using OLS and MSE as loss function. Limiting training dataset to size, book-to-market, and momentum features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.088191  0.079484 -0.015975 ...  0.071545 -0.065069 -0.076855]\n",
      "[0.00988984 0.01304656 0.01026158 ... 0.01019136 0.01856729 0.01154293]\n",
      "In sample R2 value for complete dataset is: -0.001303388414232609\n",
      "\n",
      "Out of sample R2 value for complete dataset is: 0.0017665913659755672\n",
      "\n",
      "[-0.185185 -0.0625   -0.21123  ...  0.157965 -0.171607  0.001463]\n",
      "[-0.01292972 -0.01284957 -0.01213476 ...  0.01477793  0.01477793\n",
      "  0.01477793]\n",
      "In sample R2 value for bottom performers of dataset is: 0.00025511891228668926\n",
      "\n",
      "Out of sample R2 value for bottom performers of dataset is: 0.0031842166188748022\n",
      "\n",
      "[ 0.074229 -0.068037 -0.001236 ...  0.152268  0.10736   0.010708]\n",
      "[-0.00535936 -0.00288817 -0.00249315 ...  0.0181021   0.02045904\n",
      "  0.01670873]\n",
      "In sample R2 value for top performers of dataset is: -0.0017548775387934423\n",
      "\n",
      "Out of sample R2 value for top performers of dataset is: 0.011090059339286418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtrain = [train[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "i = 0\n",
    "while i<3:\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    pred = model.predict(X=Xtest[i])\n",
    "    R2 = r2_score(y_true=Ytrue[i],y_pred=pred)\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=pred)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "        df = pd.DataFrame({'permno':test_top['permno'],'date':test_top['DATE'],'ret':test_top['RET'],'pred':pred})\n",
    "        df.to_csv('OLS_MSE_3.csv')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear model using OLS and Huber as loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickcamp/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.088191  0.079484 -0.015975 ...  0.071545 -0.065069 -0.076855]\n",
      "[0.35781891 0.20020415 0.40335709 ... 0.38817136 0.39252133 0.54733779]\n",
      "In sample R2 value for complete dataset is: -2.4180042076933956\n",
      "\n",
      "Out of sample R2 value for complete dataset is: -2.4075246628045055\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickcamp/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.185185 -0.0625   -0.21123  ...  0.157965 -0.171607  0.001463]\n",
      "[0.52568137 0.59502166 0.50835672 ... 0.56160146 0.57079655 0.51154182]\n",
      "In sample R2 value for bottom performers of dataset is: -2.224957997248551\n",
      "\n",
      "Out of sample R2 value for bottom performers of dataset is: -2.2155093696513704\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickcamp/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.074229 -0.068037 -0.001236 ...  0.152268  0.10736   0.010708]\n",
      "[ 0.19066658  0.15447693  0.17042089 ... -0.05007553  0.04742882\n",
      "  0.09150361]\n",
      "In sample R2 value for top performers of dataset is: -1.8829795073700102\n",
      "\n",
      "Out of sample R2 value for top performers of dataset is: -1.8460126898148541\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array length 71837 does not match index length 47892",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mIn sample R2 value for top performers of dataset is: \u001b[39m\u001b[39m{\u001b[39;00mR2\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOut of sample R2 value for top performers of dataset is: \u001b[39m\u001b[39m{\u001b[39;00mR2_OOS\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mpermno\u001b[39m\u001b[39m'\u001b[39m:test_top[\u001b[39m'\u001b[39m\u001b[39mpermno\u001b[39m\u001b[39m'\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m:test_top[\u001b[39m'\u001b[39m\u001b[39mDATE\u001b[39m\u001b[39m'\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mret\u001b[39m\u001b[39m'\u001b[39m:test_top[\u001b[39m'\u001b[39m\u001b[39mRET\u001b[39m\u001b[39m'\u001b[39m],\u001b[39m'\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m'\u001b[39m:pred})\n\u001b[1;32m     36\u001b[0m     df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mOLS_Huber.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     37\u001b[0m i\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    658\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    659\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    660\u001b[0m     )\n\u001b[1;32m    662\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    663\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy, typ\u001b[39m=\u001b[39mmanager)\n\u001b[1;32m    665\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    666\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39mdtype, typ\u001b[39m=\u001b[39mtyp, consolidate\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:680\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m lengths[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m    676\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    677\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marray length \u001b[39m\u001b[39m{\u001b[39;00mlengths[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m does not match index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    678\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlength \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    679\u001b[0m         )\n\u001b[0;32m--> 680\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    681\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m     index \u001b[39m=\u001b[39m default_index(lengths[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: array length 71837 does not match index length 47892"
     ]
    }
   ],
   "source": [
    "##############\n",
    "#\n",
    "#In OLS with MSE, it was found that the performance was better when using the size, book-to-market, and momentum features instead of all features.\n",
    "#Thus, will not include data for any model that uses all features, but will leave code in case user is curious about performance.\n",
    "#Note: In original report, published by S. Gu, B. Kelly, and D. Xiu\n",
    "#\n",
    "##############\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "Xtrain = [train.drop(columns=['DATE','permno','RET']).values,train_bottom.drop(columns=['DATE','permno','RET']).values,train_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test.drop(columns=['DATE','permno','RET']).values,test_bottom.drop(columns=['DATE','permno','RET']).values,test_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "i = 0\n",
    "while i<3:\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    pred = model.predict(X=Xtrain[i])\n",
    "    epsilon=np.max((np.percentile(np.abs(Ytrain[i]-pred),99.9),1))\n",
    "    model1 = linear_model.HuberRegressor(epsilon=epsilon,max_iter=1000)\n",
    "    model1.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    pred1 = model1.predict(X=Xtest[i])\n",
    "    R2 = r2_score(y_true=Ytrue[i],y_pred=pred1)\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=pred1)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "        df = pd.DataFrame({'permno':test_top['permno'],'date':test_top['DATE'],'ret':test_top['RET'],'pred':pred1})\n",
    "        df.to_csv('OLS_Huber.csv')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear model using OLS and Huber as loss function. Limiting Xtrain datasets to size, book-to-market, and momentum features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 1.0576911130990945\n",
      "[-0.088191  0.079484 -0.015975 ...  0.071545 -0.065069 -0.076855]\n",
      "[0.01020608 0.01009598 0.01111188 ... 0.01058256 0.01835172 0.05801039]\n",
      "In sample R2 value for complete dataset is: -0.0024148641934202963\n",
      "\n",
      "Out of sample R2 value for complete dataset is: 0.0006585233533125123\n",
      "\n",
      "Epsilon: 1.9093812923739626\n",
      "[-0.185185 -0.0625   -0.21123  ...  0.157965 -0.171607  0.001463]\n",
      "[-0.00280596 -0.01519182 -0.01406333 ... -0.00227047 -0.00227047\n",
      " -0.00227047]\n",
      "In sample R2 value for bottom performers of dataset is: -0.006383516118939614\n",
      "\n",
      "Out of sample R2 value for bottom performers of dataset is: -0.003434968239599323\n",
      "\n",
      "Epsilon: 1.0\n",
      "[ 0.074229 -0.068037 -0.001236 ...  0.152268  0.10736   0.010708]\n",
      "[-0.00306448 -0.00075989 -0.00110221 ...  0.01882641  0.02191942\n",
      "  0.01764656]\n",
      "In sample R2 value for top performers of dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for top performers of dataset is: 0.010371379614083964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtrain = [train[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "i = 0\n",
    "while i<3:\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    pred = model.predict(X=Xtrain[i])\n",
    "    epsilon=np.max((np.percentile(np.abs(Ytrain[i]-pred),99.9),1))\n",
    "    print(f'Epsilon: {epsilon}')\n",
    "    model1 = linear_model.HuberRegressor(epsilon=epsilon,max_iter=1000)\n",
    "    model1.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    pred1 = model1.predict(X=Xtest[i])\n",
    "    R2 = r2_score(y_true=Ytrue[i],y_pred=pred1)\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=pred1)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "        df = pd.DataFrame({'permno':test_top['permno'],'date':test_top['DATE'],'ret':test_top['RET'],'pred':pred1})\n",
    "        df.to_csv('OLS_Huber_3.csv')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model with LASSO regularization, using MSE loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = [train.drop(columns=['DATE','permno','RET']).values,train_bottom.drop(columns=['DATE','permno','RET']).values,train_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test.drop(columns=['DATE','permno','RET']).values,test_bottom.drop(columns=['DATE','permno','RET']).values,test_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "\n",
    "Xval = [val.drop(columns=['DATE','permno','RET']).values,val_bottom.drop(columns=['DATE','permno','RET']).values,val_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Yval = [val['RET'].values,val_bottom['RET'].values,val_top['RET'].values]\n",
    "\n",
    "i = 0\n",
    "alphas = 10**np.linspace(-6,6,10)\n",
    "\n",
    "while i<3:\n",
    "    best_mse = np.inf\n",
    "    best_alpha = 0\n",
    "    for alpha in alphas:\n",
    "        model = Lasso(alpha=alpha,max_iter=1000)\n",
    "        model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "        y_predVal = model.predict(X=Xval[i])\n",
    "        mse = mean_squared_error(y_true=Yval[i],y_pred=y_predVal)\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_alpha = alpha\n",
    "    model = Lasso(alpha=best_alpha,max_iter=1000)\n",
    "    print(f'best_alpha: {best_alpha}')\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    y_pred = model.predict(X=Xtest[i])\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=y_pred)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "        df = pd.DataFrame({'permno':test_top['permno'],'date':test_top['DATE'],'ret':test_top['RET'],'pred':y_pred})\n",
    "        df.to_csv('OLS_LASSO.csv')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model with LASSO regularization, using MSE as loss function. Limiting Xtrain to size, book-to-market, and momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_alpha: 0.0003511191734215131\n",
      "[-0.088191  0.079484 -0.015975 ...  0.071545 -0.065069 -0.076855]\n",
      "[0.0085248  0.0089159  0.00877782 ... 0.00788056 0.01122907 0.00932202]\n",
      "In sample R2 value for complete dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for complete dataset is: 0.0028276894578835865\n",
      "\n",
      "best_alpha: 0.0004641588833612782\n",
      "[-0.185185 -0.0625   -0.21123  ...  0.157965 -0.171607  0.001463]\n",
      "[-0.0120389  -0.01024036 -0.00982016 ...  0.00978743  0.00978743\n",
      "  0.00978743]\n",
      "In sample R2 value for bottom performers of dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for bottom performers of dataset is: 0.0033709203583318637\n",
      "\n",
      "best_alpha: 0.0004641588833612782\n",
      "[ 0.074229 -0.068037 -0.001236 ...  0.152268  0.10736   0.010708]\n",
      "[0.01032872 0.01032872 0.01032872 ... 0.01032872 0.01032872 0.01032872]\n",
      "In sample R2 value for top performers of dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for top performers of dataset is: 0.01261617282813876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtrain = [train[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "\n",
    "Xval = [val[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,val_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,val_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Yval = [val['RET'].values,val_bottom['RET'].values,val_top['RET'].values]\n",
    "\n",
    "i = 0\n",
    "alphas = 10**np.linspace(-6,6,100)\n",
    "\n",
    "while i<3:\n",
    "    best_mse = np.inf\n",
    "    best_alpha = 0\n",
    "    for alpha in alphas:\n",
    "        model = Lasso(alpha=alpha,max_iter=1000)\n",
    "        model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "        y_predVal = model.predict(X=Xval[i])\n",
    "        mse = mean_squared_error(y_true=Yval[i],y_pred=y_predVal)\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_alpha = alpha\n",
    "    print(f'best_alpha: {best_alpha}')\n",
    "    model = Lasso(alpha=best_alpha,max_iter=1000)\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    y_pred = model.predict(X=Xtest[i])\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=y_pred)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "        df = pd.DataFrame({'permno':test_top['permno'],'date':test_top['DATE'],'ret':test_top['RET'],'pred':y_pred})\n",
    "        df.to_csv('OLS_LASSO_3.csv')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model with LASSO regularization, using Huber loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = [train.drop(columns=['DATE','permno','RET']).values,train_bottom.drop(columns=['DATE','permno','RET']).values,train_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test.drop(columns=['DATE','permno','RET']).values,test_bottom.drop(columns=['DATE','permno','RET']).values,test_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "\n",
    "Xval = [val.drop(columns=['DATE','permno','RET']).values,val_bottom.drop(columns=['DATE','permno','RET']).values,val_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Yval = [val['RET'].values,val_bottom['RET'].values,val_top['RET'].values]\n",
    "\n",
    "i = 0\n",
    "gammas = 10**np.linspace(-6,6,10)\n",
    "lamdas = 10**np.linspace(-6,6,10)\n",
    "\n",
    "while i<3:\n",
    "    best_mse = np.inf\n",
    "    best_gamma=0\n",
    "    best_lamda=0\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    pred = model.predict(X=Xtrain[i])\n",
    "    epsilon=np.max((np.percentile(np.abs(Ytrain[i]-pred),99.9),1))\n",
    "    print(f'epsilon: {epsilon}')\n",
    "    for gamma in gammas:\n",
    "        for lamda in lamdas:\n",
    "            theta = prox_grad(gamma=gamma,lamda=lamda,X=Xtrain[i],y=Ytrain[i],model='lasso',loss_type='huber',epsilon=epsilon)\n",
    "            pred = fit_APG(Xtest=Xval[i],theta=theta)\n",
    "            loss = HuberLoss(true=Yval[i],pred=pred,epsilon=epsilon)\n",
    "            if loss < best_mse:\n",
    "                best_mse = loss\n",
    "                best_gamma = gamma\n",
    "                best_lamda = lamda\n",
    "    print(f'best gamma: {best_gamma}\\nbest lamda: {best_lamda}')\n",
    "    theta = prox_grad(gamma=best_gamma,lamda=best_lamda,X=Xtrain[i],y=Ytrain[i],model='lasso',loss_type='huber',epsilon=epsilon)\n",
    "    pred = fit_APG(Xtest=Xtest[i],theta=theta)\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=pred)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model with LASSO regularization, using Huber loss function. Limitng X dataset to size, book-to-market, and momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 1.0576911130990945\n",
      "best gamma: 100.0\n",
      "best lamda: 1e-06\n",
      "0.020156711366922694\n",
      "[-0.088191  0.079484 -0.015975 ...  0.071545 -0.065069 -0.076855]\n",
      "[1.86568174e-05 1.99576846e-05 1.85168470e-05 ... 1.82145396e-05\n",
      " 1.91744894e-05 4.71208837e-06]\n",
      "Out of sample R2 value for complete dataset is: 1.0403974521122628e-05\n",
      "\n",
      "epsilon: 1.9093812923739626\n",
      "best gamma: 1e-06\n",
      "best lamda: 0.01\n",
      "0.05137084521349965\n",
      "[-0.185185 -0.0625   -0.21123  ...  0.157965 -0.171607  0.001463]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "Out of sample R2 value for bottom performers of dataset is: 0.0\n",
      "\n",
      "epsilon: 1.0\n",
      "best gamma: 1e-06\n",
      "best lamda: 1e-06\n",
      "0.005790145392873892\n",
      "[ 0.074229 -0.068037 -0.001236 ...  0.152268  0.10736   0.010708]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "Out of sample R2 value for top performers of dataset is: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtrain = [train[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "\n",
    "Xval = [val[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,val_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,val_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Yval = [val['RET'].values,val_bottom['RET'].values,val_top['RET'].values]\n",
    "\n",
    "i = 0\n",
    "gammas = 10**np.linspace(-6,6,10)\n",
    "lamdas = 10**np.linspace(-6,6,10)\n",
    "\n",
    "while i<3:\n",
    "    best_mse = np.inf\n",
    "    best_gamma=0\n",
    "    best_lamda=0\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    pred = model.predict(X=Xtrain[i])\n",
    "    epsilon=np.max((np.percentile(np.abs(Ytrain[i]-pred),99.9),1))\n",
    "    print(f'epsilon: {epsilon}')\n",
    "    for gamma in gammas:\n",
    "        for lamda in lamdas:\n",
    "            theta = prox_grad(gamma=gamma,lamda=lamda,X=Xtrain[i],y=Ytrain[i],model='lasso',loss_type='huber',epsilon=epsilon)\n",
    "            pred = fit_APG(Xtest=Xval[i],theta=theta)\n",
    "            loss = HuberLoss(true=Yval[i],pred=pred,epsilon=epsilon)\n",
    "            if loss < best_mse:\n",
    "                best_mse = loss\n",
    "                best_gamma = gamma\n",
    "                best_lamda = lamda\n",
    "    print(f'best gamma: {best_gamma}\\nbest lamda: {best_lamda}')\n",
    "    print(loss)\n",
    "    theta = prox_grad(gamma=best_gamma,lamda=best_lamda,X=Xtrain[i],y=Ytrain[i],model='lasso',loss_type='huber',epsilon=epsilon)\n",
    "    pred = fit_APG(Xtest=Xtest[i],theta=theta)\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=pred)\n",
    "    if i == 0:\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model with Ridge regularization, using MSE loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = [train.drop(columns=['DATE','permno','RET']).values,train_bottom.drop(columns=['DATE','permno','RET']).values,train_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test.drop(columns=['DATE','permno','RET']).values,test_bottom.drop(columns=['DATE','permno','RET']).values,test_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "\n",
    "Xval = [val.drop(columns=['DATE','permno','RET']).values,val_bottom.drop(columns=['DATE','permno','RET']).values,val_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Yval = [val['RET'].values,val_bottom['RET'].values,val_top['RET'].values]\n",
    "\n",
    "i = 0\n",
    "alphas = 10**np.linspace(-6,6,10)\n",
    "\n",
    "while i<3:\n",
    "    best_mse = np.inf\n",
    "    best_alpha = 0\n",
    "    for alpha in alphas:\n",
    "        model = Ridge(alpha=alpha,max_iter=1000)\n",
    "        model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "        y_predVal = model.predict(X=Xval[i])\n",
    "        mse = mean_squared_error(y_true=Yval[i],y_pred=y_predVal)\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_alpha = alpha\n",
    "    print(f'best_alpha: {best_alpha}')\n",
    "    model = Ridge(alpha=best_alpha,max_iter=1000)\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    y_pred = model.predict(X=Xtest[i])\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=y_pred)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model with Ridge regularization, using MSE as loss function. Limiting Xtrain to size, mook-to-market, and momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_alpha: 46415.888336127915\n",
      "[-0.088191  0.079484 -0.015975 ...  0.071545 -0.065069 -0.076855]\n",
      "[0.00857403 0.0090085  0.0087027  ... 0.00816591 0.0102446  0.00787592]\n",
      "In sample R2 value for complete dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for complete dataset is: 0.0028872231080153687\n",
      "\n",
      "best_alpha: 2848.035868435805\n",
      "[-0.185185 -0.0625   -0.21123  ...  0.157965 -0.171607  0.001463]\n",
      "[-0.01130761 -0.00815716 -0.00824147 ...  0.01103922  0.01103922\n",
      "  0.01103922]\n",
      "In sample R2 value for bottom performers of dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for bottom performers of dataset is: 0.0034148308470604016\n",
      "\n",
      "best_alpha: 1000000.0\n",
      "[ 0.074229 -0.068037 -0.001236 ...  0.152268  0.10736   0.010708]\n",
      "[0.01031627 0.01032001 0.01031745 ... 0.01033639 0.01034118 0.01033548]\n",
      "In sample R2 value for top performers of dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for top performers of dataset is: 0.012619944371153324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtrain = [train[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "\n",
    "Xval = [val[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,val_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,val_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Yval = [val['RET'].values,val_bottom['RET'].values,val_top['RET'].values]\n",
    "\n",
    "i = 0\n",
    "alphas = 10**np.linspace(-6,6,100)\n",
    "\n",
    "while i<3:\n",
    "    best_mse = np.inf\n",
    "    best_alpha = 0\n",
    "    for alpha in alphas:\n",
    "        model = Ridge(alpha=alpha,max_iter=1000)\n",
    "        model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "        y_predVal = model.predict(X=Xval[i])\n",
    "        mse = mean_squared_error(y_true=Yval[i],y_pred=y_predVal)\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_alpha = alpha\n",
    "    print(f'best_alpha: {best_alpha}')\n",
    "    model = Ridge(alpha=best_alpha,max_iter=1000)\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    y_pred = model.predict(X=Xtest[i])\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=y_pred)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "        df = pd.DataFrame({'permno':test_top['permno'],'date':test_top['DATE'],'ret':test_top['RET'],'pred':y_pred})\n",
    "        df.to_csv('OLS_Ridge_3.csv')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model with Ridge regularization, using Huber loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = [train.drop(columns=['DATE','permno','RET']).values,train_bottom.drop(columns=['DATE','permno','RET']).values,train_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test.drop(columns=['DATE','permno','RET']).values,test_bottom.drop(columns=['DATE','permno','RET']).values,test_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "\n",
    "Xval = [val.drop(columns=['DATE','permno','RET']).values,val_bottom.drop(columns=['DATE','permno','RET']).values,val_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Yval = [val['RET'].values,val_bottom['RET'].values,val_top['RET'].values]\n",
    "\n",
    "i = 0\n",
    "gammas = 10**np.linspace(-6,6,10)\n",
    "lamdas = 10**np.linspace(-6,6,10)\n",
    "\n",
    "while i<3:\n",
    "    best_mse = np.inf\n",
    "    best_gamma=0\n",
    "    best_lamda=0\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    pred = model.predict(X=Xtrain[i])\n",
    "    epsilon=np.max((np.percentile(np.abs(Ytrain[i]-pred),99.9),1))\n",
    "    print(f'epsilon: {epsilon}')\n",
    "    for gamma in gammas:\n",
    "        for lamda in lamdas:\n",
    "            theta = prox_grad(gamma=gamma,lamda=lamda,X=Xtrain[i],y=Ytrain[i],model='ridge',loss_type='huber',epsilon=epsilon)\n",
    "            pred = fit_APG(Xtest=Xval[i],theta=theta)\n",
    "            loss = HuberLoss(true=Yval[i],pred=pred,epsilon=epsilon)\n",
    "            if loss < best_mse:\n",
    "                best_mse = loss\n",
    "                best_gamma = gamma\n",
    "                best_lamda = lamda\n",
    "    print(f'best gamma: {best_gamma}\\nbest lamda: {best_lamda}')\n",
    "    theta = prox_grad(gamma=best_gamma,lamda=best_lamda,X=Xtrain[i],y=Ytrain[i],model='ridge',loss_type='huber',epsilon=epsilon)\n",
    "    pred = fit_APG(Xtest=Xtest[i],theta=theta)\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=pred)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model with Ridge regularization, using Huber loss function. Limiting X dataset to size, book-to-market, and momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 1.0576911130990945\n",
      "best gamma: 0.00046415888336127773\n",
      "best lamda: 1000000.0\n",
      "[-0.088191  0.079484 -0.015975 ...  0.071545 -0.065069 -0.076855]\n",
      "[-8.87700998e-09 -9.86978773e-09 -8.85303344e-09 ... -8.48446420e-09\n",
      " -9.55011094e-09 -2.78550912e-09]\n",
      "In sample R2 value for complete dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for complete dataset is: -4.982344092852031e-09\n",
      "\n",
      "epsilon: 1.9093812923739626\n",
      "best gamma: 0.00046415888336127773\n",
      "best lamda: 1000000.0\n",
      "[-0.185185 -0.0625   -0.21123  ...  0.157965 -0.171607  0.001463]\n",
      "[-5.38309243e-09 -7.50872042e-09 -7.06923518e-09 ... -1.12671837e-08\n",
      " -1.12671837e-08 -1.12671837e-08]\n",
      "In sample R2 value for bottom performers of dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for bottom performers of dataset is: -3.9465171131070065e-09\n",
      "\n",
      "epsilon: 1.0\n",
      "best gamma: 1e-06\n",
      "best lamda: 1e-06\n",
      "[ 0.074229 -0.068037 -0.001236 ...  0.152268  0.10736   0.010708]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "In sample R2 value for top performers of dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for top performers of dataset is: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtrain = [train[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "\n",
    "Xval = [val[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,val_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,val_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Yval = [val['RET'].values,val_bottom['RET'].values,val_top['RET'].values]\n",
    "\n",
    "i = 0\n",
    "gammas = 10**np.linspace(-6,6,10)\n",
    "lamdas = 10**np.linspace(-6,6,10)\n",
    "\n",
    "while i<3:\n",
    "    best_mse = np.inf\n",
    "    best_gamma=0\n",
    "    best_lamda=0\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    pred = model.predict(X=Xtrain[i])\n",
    "    epsilon=np.max((np.percentile(np.abs(Ytrain[i]-pred),99.9),1))\n",
    "    print(f'epsilon: {epsilon}')\n",
    "    for gamma in gammas:\n",
    "        for lamda in lamdas:\n",
    "            theta = prox_grad(gamma=gamma,lamda=lamda,X=Xtrain[i],y=Ytrain[i],model='ridge',loss_type='huber',epsilon=epsilon)\n",
    "            pred = fit_APG(Xtest=Xval[i],theta=theta)\n",
    "            loss = HuberLoss(true=Yval[i],pred=pred,epsilon=epsilon)\n",
    "            if loss < best_mse:\n",
    "                best_mse = loss\n",
    "                best_gamma = gamma\n",
    "                best_lamda = lamda\n",
    "    print(f'best gamma: {best_gamma}\\nbest lamda: {best_lamda}')\n",
    "    theta = prox_grad(gamma=best_gamma,lamda=best_lamda,X=Xtrain[i],y=Ytrain[i],model='ridge',loss_type='huber',epsilon=epsilon)\n",
    "    pred = fit_APG(Xtest=Xtest[i],theta=theta)\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=pred)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model with Elastic Net regularization, using MSE loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = [train.drop(columns=['DATE','permno','RET']).values,train_bottom.drop(columns=['DATE','permno','RET']).values,train_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test.drop(columns=['DATE','permno','RET']).values,test_bottom.drop(columns=['DATE','permno','RET']).values,test_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "\n",
    "Xval = [val.drop(columns=['DATE','permno','RET']).values,val_bottom.drop(columns=['DATE','permno','RET']).values,val_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Yval = [val['RET'].values,val_bottom['RET'].values,val_top['RET'].values]\n",
    "\n",
    "alphas = 10**np.linspace(-6,6,10)\n",
    "l1_ratios = 10**np.linspace(-6,0,10)\n",
    "\n",
    "i=0\n",
    "while i < 3:\n",
    "    best_mse = 0\n",
    "    best_alpha = 0\n",
    "    best_l1_ratio = 0\n",
    "    for alpha in alphas:\n",
    "        for l1_ratio in l1_ratios:\n",
    "            model = ElasticNet(alpha=alpha,l1_ratio=l1_ratio,max_iter=1000)\n",
    "            model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "            y_predVal = model.predict(Xval[i])\n",
    "            mse = mean_squared_error(y_true=Yval[i],y_pred=y_predVal)\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_alpha = alpha\n",
    "                best_l1_ratio = l1_ratio\n",
    "    print(f'best alpha: {best_alpha}\\nbest l1_ratio: {best_l1_ratio}')\n",
    "    model = ElasticNet(alpha=best_alpha,l1_ratio=best_l1_ratio,max_iter=1000)\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    y_pred = model.predict(X=Xtest[i])\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=y_pred)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model with Elastic Net regularization, using MSE as loss function. Limiting X datasets to size, book-to-market, and momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha: 0.07054802310718646\n",
      "best l1_ratio: 0.0014174741629268048\n",
      "[-0.088191  0.079484 -0.015975 ...  0.071545 -0.065069 -0.076855]\n",
      "[0.00860455 0.00891386 0.00878506 ... 0.00811736 0.01050056 0.00910094]\n",
      "In sample R2 value for complete dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for complete dataset is: 0.0028713563564116695\n",
      "\n",
      "best alpha: 0.030538555088334186\n",
      "best l1_ratio: 0.002848035868435802\n",
      "[-0.185185 -0.0625   -0.21123  ...  0.157965 -0.171607  0.001463]\n",
      "[-0.01141986 -0.00868664 -0.00882123 ...  0.01110221  0.01110221\n",
      "  0.01110221]\n",
      "In sample R2 value for bottom performers of dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for bottom performers of dataset is: 0.0034253929172095576\n",
      "\n",
      "best alpha: 0.0004641588833612782\n",
      "best l1_ratio: 1.0\n",
      "[ 0.074229 -0.068037 -0.001236 ...  0.152268  0.10736   0.010708]\n",
      "[0.01032872 0.01032872 0.01032872 ... 0.01032872 0.01032872 0.01032872]\n",
      "In sample R2 value for top performers of dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for top performers of dataset is: 0.01261617282813876\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtrain = [train[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "\n",
    "Xval = [val[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,val_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,val_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Yval = [val['RET'].values,val_bottom['RET'].values,val_top['RET'].values]\n",
    "\n",
    "alphas = 10**np.linspace(-6,6,100)\n",
    "l1_ratios = 10**np.linspace(-6,0,100)\n",
    "i=0\n",
    "while i < 3:\n",
    "    best_mse = np.inf\n",
    "    best_alpha = 0\n",
    "    best_l1_ratio = 0\n",
    "    for alpha in alphas:\n",
    "        for l1_ratio in l1_ratios:\n",
    "            model = ElasticNet(alpha=alpha,l1_ratio=l1_ratio,max_iter=1000)\n",
    "            model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "            y_predVal = model.predict(Xval[i])\n",
    "            mse = mean_squared_error(y_true=Yval[i],y_pred=y_predVal)\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_alpha = alpha\n",
    "                best_l1_ratio = l1_ratio\n",
    "    print(f'best alpha: {best_alpha}\\nbest l1_ratio: {best_l1_ratio}')\n",
    "    model = ElasticNet(alpha=best_alpha,l1_ratio=best_l1_ratio,max_iter=1000)\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    y_pred = model.predict(X=Xtest[i])\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=y_pred)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "        df = pd.DataFrame({'permno':test_top['permno'],'date':test_top['DATE'],'ret':test_top['RET'],'pred':y_pred})\n",
    "        df.to_csv('OLS_ENet_3.csv')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model with Elastic Net reuglarization, using Huber loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = [train.drop(columns=['DATE','permno','RET']).values,train_bottom.drop(columns=['DATE','permno','RET']).values,train_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test.drop(columns=['DATE','permno','RET']).values,test_bottom.drop(columns=['DATE','permno','RET']).values,test_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "\n",
    "Xval = [val.drop(columns=['DATE','permno','RET']).values,val_bottom.drop(columns=['DATE','permno','RET']).values,val_top.drop(columns=['DATE','permno','RET']).values]\n",
    "Yval = [val['RET'].values,val_bottom['RET'].values,val_top['RET'].values]\n",
    "\n",
    "i = 0\n",
    "gammas = 10**np.linspace(-6,6,10)\n",
    "lamdas = 10**np.linspace(-6,6,10)\n",
    "l1_ratios = 10**np.linspace(-6,0,10)\n",
    "\n",
    "while i<3:\n",
    "    best_mse = np.inf\n",
    "    best_gamma=0\n",
    "    best_lamda=0\n",
    "    best_l1_ratio = 0\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    pred = model.predict(X=Xtrain[i])\n",
    "    epsilon=np.max((np.percentile(np.abs(Ytrain[i]-pred),99.9),1))\n",
    "    for gamma in gammas:\n",
    "        for lamda in lamdas:\n",
    "            for rho in l1_ratios:\n",
    "                theta = prox_grad(gamma=gamma,lamda=lamda,X=Xtrain[i],y=Ytrain[i],model='elastic',loss_type='huber',epsilon=epsilon,rho=rho)\n",
    "                pred = fit_APG(Xtest=Xval[i],theta=theta)\n",
    "                loss = HuberLoss(true=Yval[i],pred=pred,epsilon=epsilon)\n",
    "                if loss < best_mse:\n",
    "                    best_mse = loss\n",
    "                    best_gamma = gamma\n",
    "                    best_lamda = lamda\n",
    "                    best_l1_ratio = rho\n",
    "    theta = prox_grad(gamma=best_gamma,lamda=best_lamda,X=Xtrain[i],y=Ytrain[i],model='elastic',loss_type='huber',epsilon=epsilon,rho=best_l1_ratio)\n",
    "    pred = fit_APG(Xtest=Xtest[i],theta=theta)\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=pred)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Model with Elastic Net regularization, using Huber loss function. Limiting X dataset to size, book-to-market, momentum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.088191  0.079484 -0.015975 ...  0.071545 -0.065069 -0.076855]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "In sample R2 value for complete dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for complete dataset is: 0.0\n",
      "\n",
      "[-0.185185 -0.0625   -0.21123  ...  0.157965 -0.171607  0.001463]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "In sample R2 value for bottom performers of dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for bottom performers of dataset is: 0.0\n",
      "\n",
      "[ 0.074229 -0.068037 -0.001236 ...  0.152268  0.10736   0.010708]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "In sample R2 value for top performers of dataset is: -0.0024828921845239105\n",
      "\n",
      "Out of sample R2 value for top performers of dataset is: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtrain = [train[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,train_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrain = [train['RET'].values,train_bottom['RET'].values,train_top['RET'].values]\n",
    "\n",
    "Xtest = [test[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,test_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Ytrue = [test['RET'].values,test_bottom['RET'].values,test_top['RET'].values]\n",
    "\n",
    "Xval = [val[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,val_bottom[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values,val_top[['mvel1','bm','mom1m','mom6m','mom12m','mom36m']].values]\n",
    "Yval = [val['RET'].values,val_bottom['RET'].values,val_top['RET'].values]\n",
    "\n",
    "i = 0\n",
    "gammas = 10**np.linspace(-6,6,10)\n",
    "lamdas = 10**np.linspace(-6,6,10)\n",
    "l1_ratios = 10**np.linspace(-6,0,10)\n",
    "\n",
    "while i<3:\n",
    "    best_mse = np.inf\n",
    "    best_gamma=0\n",
    "    best_lamda=0\n",
    "    best_l1_ratio = 0\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X=Xtrain[i],y=Ytrain[i])\n",
    "    pred = model.predict(X=Xtrain[i])\n",
    "    epsilon=np.max((np.percentile(np.abs(Ytrain[i]-pred),99.9),1))\n",
    "    for gamma in gammas:\n",
    "        for lamda in lamdas:\n",
    "            for rho in l1_ratios:\n",
    "                theta = prox_grad(gamma=gamma,lamda=lamda,X=Xtrain[i],y=Ytrain[i],model='elastic',loss_type='huber',epsilon=epsilon,rho=rho)\n",
    "                pred = fit_APG(Xtest=Xval[i],theta=theta)\n",
    "                loss = HuberLoss(true=Yval[i],pred=pred,epsilon=epsilon)\n",
    "                if loss < best_mse:\n",
    "                    best_mse = loss\n",
    "                    best_gamma = gamma\n",
    "                    best_lamda = lamda\n",
    "                    best_l1_ratio = rho\n",
    "    theta = prox_grad(gamma=best_gamma,lamda=best_lamda,X=Xtrain[i],y=Ytrain[i],model='elastic',loss_type='huber',epsilon=epsilon,rho=best_l1_ratio)\n",
    "    pred = fit_APG(Xtest=Xtest[i],theta=theta)\n",
    "    R2_OOS = R_oss(true=Ytrue[i],pred=pred)\n",
    "    if i == 0:\n",
    "        print(f'In sample R2 value for complete dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for complete dataset is: {R2_OOS}\\n')\n",
    "    if i == 1:\n",
    "        print(f'In sample R2 value for bottom performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for bottom performers of dataset is: {R2_OOS}\\n')\n",
    "    if i == 2:\n",
    "        print(f'In sample R2 value for top performers of dataset is: {R2}\\n')\n",
    "        print(f'Out of sample R2 value for top performers of dataset is: {R2_OOS}\\n')\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
